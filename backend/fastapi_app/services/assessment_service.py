# backend/fastapi_app/services/assessment_service.py

from typing import Dict, List, Any, Union
from tempfile import NamedTemporaryFile
from fastapi import UploadFile, HTTPException, Request
from fastapi_app.schemas.test_schemas import PreferenceData, FinalAssessmentSubmission, QuizQuestion 
import os
import json
import logging
from google import genai
from google.genai import types as g_types
from starlette.concurrency import run_in_threadpool
from google.genai.errors import APIError
import base64, mimetypes
from fastapi_app.database import admin_supabase
from fastapi_app.prompts.roadmap import build_roadmap_prompt, build_roadmap_adjustment_prompt
import anyio
import re # Import thÆ° viá»‡n regex

logger = logging.getLogger(__name__)

# Táº­n dá»¥ng client Ä‘Ã£ khá»Ÿi táº¡o á»Ÿ pháº¡m vi global tá»« test_service
try:
    from .test_service import client, GEMINI_MODEL 
except ImportError:
    client = None
    # GEMINI_MODEL = "gemini-2.0-flash"


# --- HÃ€M 1: STT VÃ€ PHÃ‚N TÃCH TRANSCRIPT ---
    
# --- HÃ€M 2: CHáº¤M ÄIá»‚M TRáº®C NGHIá»†M THá»°C Táº¾ ---

def calculate_mcq_score(
    mcq_answers: Dict[str, str] | None, 
    quiz_questions: List[QuizQuestion] 
) -> Dict[str, Any]: 
    """HÃ m tÃ­nh Ä‘iá»ƒm tráº¯c nghiá»‡m (MCQ) báº±ng cÃ¡ch so sÃ¡nh vá»›i cÃ¢u tráº£ lá»i LLM."""
    
    if mcq_answers is None:
        mcq_answers = {}
        
    total_answered = len(mcq_answers)
    correct_count = 0
    topic_results = {} 
    
    correct_data_map = {}
    for q in quiz_questions:
        if q.question_type != 'speaking_prompt':
            correct_data_map[str(q.id)] = {
                'correct_key': q.correct_answer_key, 
                'topic': q.question_type 
            }
            
    for q_id, user_key in mcq_answers.items():
        quiz_data = correct_data_map.get(q_id)
        
        if quiz_data:
            topic = quiz_data['topic']
            correct_answer = quiz_data['correct_key']
            
            if topic not in topic_results:
                topic_results[topic] = [0, 0]  # [correct, total]
            
            topic_results[topic][1] += 1
            
            if correct_answer == user_key:
                correct_count += 1
                topic_results[topic][0] += 1
            
    weak_topics = []
    WEAK_THRESHOLD = 0.60 
    
    for topic, (correct, total) in topic_results.items():
        if total > 0 and (correct / total) < WEAK_THRESHOLD:
            weak_topics.append(f"{topic} (ÄÃºng: {correct}/{total})")

    if not weak_topics and total_answered > 0:
          weak_topics.append("KhÃ´ng phÃ¡t hiá»‡n Ä‘iá»ƒm yáº¿u lá»›n á»Ÿ pháº§n tráº¯c nghiá»‡m.")

    score_percent = (correct_count / total_answered) * 100 if total_answered > 0 else 0
    
    return {
        "score_percent": score_percent,
        "correct_count": correct_count,
        "total_questions": total_answered,
        "weak_topics": weak_topics,
        # "estimated_level": "Intermediate (B1)" if score_percent >= 60 else "Pre-Intermediate (A2)",
    }

# -----------------------------------------------------------------
def initialize_user_progress(learning_phases: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    QuÃ©t qua toÃ n bá»™ learning_phases vÃ  khá»Ÿi táº¡o tráº¡ng thÃ¡i tiáº¿n Ä‘á»™ ban Ä‘áº§u cho 
    táº¥t cáº£ cÃ¡c lesson_id tÃ¬m tháº¥y.
    """
    user_progress = {}
    
    # 1. Láº·p qua cÃ¡c Giai Ä‘oáº¡n (Phases)
    for phase in learning_phases:
        for week in phase.get("weeks", []):
            
            # 2. Láº·p qua cÃ¡c Ká»¹ nÄƒng (Grammar, Vocab, Speaking)
            for skill_type in ["grammar", "vocabulary", "speaking"]:
                skill_data = week.get(skill_type)
                
                if skill_data and skill_data.get("items"):
                    # 3. Láº·p qua cÃ¡c Items (BÃ i há»c)
                    for item in skill_data["items"]:
                        lesson_id = item.get("lesson_id")
                        
                        if lesson_id and lesson_id not in user_progress:
                            # 4. Khá»Ÿi táº¡o tráº¡ng thÃ¡i ban Ä‘áº§u
                            user_progress[lesson_id] = {
                                "completed": False, 
                                "score": None,
                                "type": skill_type, # LÆ°u loáº¡i ká»¹ nÄƒng Ä‘á»ƒ dá»… truy váº¥n sau nÃ y
                                "attempt_count": 0,
                                "status": "PENDING"
                            }
                            
    return user_progress
async def analyze_speaking_audio(audio_path: str, client):
    def _sync_call():
        with open(audio_path, "rb") as f:
            audio_bytes = f.read()

        return client.models.generate_content(
            model="gemini-2.5-flash-preview-09-2025",
            contents=[
                {
                    "role": "user",
                    "parts": [
                        {
                            "text": """
                            You are an English speaking assessment engine.

                            Tasks:
                            1. Transcribe the audio.
                            2. Give a SHORT overall evaluation of speaking ability.
                            3. Identify MAIN speaking weaknesses based on grammar, vocabulary, pronunciation, or fluency.

                            Return ONLY valid JSON:
                            {
                            "transcript": "",
                            "speaking_overall": "",
                            "speaking_weakness": []
                            }

                            Rules:
                            - speaking_overall: 1â€“2 sentences
                            - speaking_weakness: list of short phrases (can be empty)
                            - No scores
                            - No word count
                            """
                        },
                        {
                            "inline_data": {
                                "mime_type": "audio/mpeg",
                                "data": audio_bytes
                            }
                        }
                    ]
                }
            ],
        )

    try:
        response = await run_in_threadpool(_sync_call)
        raw_text = response.text.strip()

        if raw_text.startswith("```"):
            raw_text = raw_text.replace("```json", "").replace("```", "").strip()

        data = json.loads(raw_text)

        return {
            "transcript": data.get("transcript", ""),
            "speaking_overall": data.get(
                "speaking_overall",
                "Speaking ability could not be fully assessed."
            ),
            "speaking_weakness": data.get("speaking_weakness", []),
        }

    except Exception as e:
        logger.error(f"[Speaking Gemini Error] {e}")

        # ğŸ”¥ FALLBACK QUAN TRá»ŒNG
        return {
            "transcript": "",
            "speaking_overall": "Speaking assessment is temporarily unavailable due to system limits."
        }
async def analyze_and_generate_roadmap(
    payload_data: FinalAssessmentSubmission,
    audio_files: Dict[str, UploadFile]
) -> Dict[str, Any]:
    if client is None:
        raise HTTPException(status_code=500, detail="Gemini Client khÃ´ng kháº£ dá»¥ng.")

    # Chá»‰ log audio files
    logger.info(f"ğŸ“Œ FILE MAP NHáº¬N Tá»ª FRONTEND: {list(audio_files.keys())}")

    # --- 1. PHÃ‚N TÃCH MCQ ---
    mcq_analysis = calculate_mcq_score(payload_data.mcq_answers, payload_data.quiz_questions)
    diagnostic_summary = mcq_analysis 
    
    # --- 2. Xá»¬ LÃ SPEAKING ---
    full_speaking_analysis = []

    if audio_files and payload_data.speaking_data:
        for speaking_data_item in payload_data.speaking_data:
            raw_key = speaking_data_item.file_key

            # Fallback: chá»‰ láº¥y file Ä‘áº§u tiÃªn náº¿u FE gá»­i 1 file
            audio_file = next(iter(audio_files.values()), None)

            if not audio_file:
                logger.warning(f"[Speaking] No audio found for Q{raw_key}")
                continue

            tmp_path = None
            try:
                file_bytes = await audio_file.read()
                suffix = os.path.splitext(audio_file.filename)[1] or ".mp3"

                with NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                    tmp_path = tmp.name
                    await run_in_threadpool(tmp.write, file_bytes)

                speaking_result = await analyze_speaking_audio(tmp_path, client)

                # Náº¿u khÃ´ng cÃ³ lá»i nÃ³i â†’ bá» qua
                if not speaking_result.get("transcript") and speaking_result.get("status") == "FALLBACK":
                    logger.warning(f"[Speaking] Gemini unavailable for Q{raw_key} (quota or overload)")

                full_speaking_analysis.append({
                    "question_id": raw_key,
                    "transcript": speaking_result["transcript"],
                    "speaking_overall": speaking_result["speaking_overall"],
                    "latency_s": speaking_data_item.latency_ms / 1000,
                    "status": "OK",
                })

            except Exception as e:
                logger.warning(f"[Speaking] Failed Q{raw_key}: {e}")

            finally:
                if tmp_path and os.path.exists(tmp_path):
                    try:
                        os.unlink(tmp_path)
                    except:
                        pass

    
    # --- 3. XÃ‚Y Dá»°NG PROMPT CHO GEMINI vÃ  táº¡o roadmap ---
    prefs = payload_data.preferences
    prefs_dict = prefs.model_dump()

    weak_points_list = list(mcq_analysis.get('weak_topics', []))
    has_speaking = len(full_speaking_analysis) > 0

    speaking_overall = (
        full_speaking_analysis[0]["speaking_overall"]
        if has_speaking
        else "KhÃ´ng cÃ³ Ä‘Ã¡nh giÃ¡ speaking."
    )

    for weakness in speaking_result.get("speaking_weakness", []):
        weak_points_list.append(f"Speaking: {weakness}")
    # Cáº¬P NHáº¬T PROMPT Äá»‚ Táº O Cáº¤U TRÃšC JSON CHI TIáº¾T THEO YÃŠU Cáº¦U
    roadmap_prompt = build_roadmap_prompt(
        mcq_analysis=mcq_analysis,
        weak_points_list=weak_points_list,
        speaking_overall=speaking_overall,
        prefs_dict=prefs_dict,
    )

    try:
        roadmap_response = await run_in_threadpool(
            client.models.generate_content,
            model="gemini-2.5-flash-preview-09-2025",
            contents=[roadmap_prompt],
            config=g_types.GenerateContentConfig(response_mime_type="application/json")
        )

        roadmap_json = json.loads(roadmap_response.text)
        ai_assessed_level = roadmap_json.get("estimated_level", "Unknown")
        user_summary = roadmap_json.get("user_summary", "KhÃ´ng cÃ³ tÃ³m táº¯t.")
        raw_roadmap = roadmap_json.get("roadmap", {})

        # Cáº¬P NHáº¬T LOGIC Xá»¬ LÃ: TRÃCH XUáº¤T TRá»°C TIáº¾P Cáº¤U TRÃšC TUáº¦N
        final_learning_phases = []
        for idx, phase in enumerate(raw_roadmap.get("learning_phases", [])):
            phase_name = phase.get("phase_name") or f"Giai Ä‘oáº¡n {idx + 1}"
            duration_weeks = phase.get("duration_weeks", 0)
            weeks = phase.get("weeks", [])

            # Äáº£m báº£o cáº¥u trÃºc tuáº§n Ä‘Æ°á»£c giá»¯ nguyÃªn, sá»­ dá»¥ng Dict cho grammar/vocab/speaking
            standardized_weeks = []
            for week in weeks:
                standardized_weeks.append({
                    "week_number": week.get("week_number"),
                    "grammar": week.get("grammar", {}), # Láº¥y dÆ°á»›i dáº¡ng Dict, máº·c Ä‘á»‹nh lÃ  {}
                    "vocabulary": week.get("vocabulary", {}), # Láº¥y dÆ°á»›i dáº¡ng Dict, máº·c Ä‘á»‹nh lÃ  {}
                    "speaking": week.get("speaking", {}), # Láº¥y dÆ°á»›i dáº¡ng Dict, máº·c Ä‘á»‹nh lÃ  {}
                    "expected_outcome": week.get("expected_outcome", "")
                })

            final_learning_phases.append({
                "phase_name": phase_name,
                "duration_weeks": duration_weeks,
                "weeks": standardized_weeks,
            })
        # Chuáº©n bá»‹ roadmap cuá»‘i cÃ¹ng Ä‘á»ƒ lÆ°u
        initial_progress = initialize_user_progress(final_learning_phases)

        final_roadmap = {
            "user_summary": user_summary, 
            "level": ai_assessed_level,
            "summary": raw_roadmap.get("summary", "TÃ³m táº¯t khÃ´ng cÃ³ sáºµn do lá»—i LLM."),
            "current_status": raw_roadmap.get("current_status", f"Má»¥c tiÃªu: {prefs_dict['communication_goal']}, Thá»i gian: {prefs_dict['target_duration']}"),
            "daily_plan_recommendation": raw_roadmap.get("daily_plan_recommendation", f"Khuyáº¿n nghá»‹: Há»c {prefs_dict['daily_commitment']} má»—i ngÃ y."),
            "learning_phases": final_learning_phases,
            "diagnostic_summary": mcq_analysis,
            "speaking_transcripts": full_speaking_analysis,
            "user_progress": initial_progress,  
        }
        
        # --- 4. LÆ¯U ROADMAP VÃ€O admin_supabase ---
        try:
            # 1. Thá»±c hiá»‡n xoÃ¡ táº¥t cáº£ roadmap hiá»‡n cÃ³ cá»§a user nÃ y
            # Lá»‡nh delete sáº½ xoÃ¡ táº¥t cáº£ dÃ²ng khá»›p vá»›i user_id
            admin_supabase.table("roadmaps") \
                .delete() \
                .eq("user_id", payload_data.user_id) \
                .execute()
            
            logger.info(f"ğŸ—‘ï¸ ÄÃ£ xoÃ¡ lá»™ trÃ¬nh cÅ© cá»§a user {payload_data.user_id}")

            # 2. Chuáº©n bá»‹ dá»¯ liá»‡u má»›i hoÃ n toÃ n
            insert_data = {
                "user_id": payload_data.user_id,
                "level": ai_assessed_level,
                "data": final_roadmap,
            }

            # 3. ChÃ¨n (Insert) báº£n ghi má»›i nháº¥t vÃ o báº£ng
            result = admin_supabase.table("roadmaps") \
                .insert(insert_data) \
                .execute()
            
            logger.info(f"âœ¨ ÄÃ£ lÆ°u lá»™ trÃ¬nh má»›i thÃ nh cÃ´ng cho user {payload_data.user_id}")

        except Exception as e:
            # Ghi log chi tiáº¿t lá»—i náº¿u thao tÃ¡c database tháº¥t báº¡i
            logger.error(f"âŒ Lá»—i khi lÃ m má»›i roadmap trong admin_supabase: {e}")
            
        return {
            "status": "success",
            "message": "Roadmap created",
            "roadmap_details": {
                "roadmap": final_roadmap,
                "diagnostic_summary": mcq_analysis
            },
            "diagnostic_summary": mcq_analysis,
            "speaking_transcripts": full_speaking_analysis
        }

    except json.JSONDecodeError as e:
        # Log Ä‘áº§y Ä‘á»§ response text náº¿u cÃ³ thá»ƒ Ä‘á»ƒ debug lá»—i JSON
        if 'roadmap_response' in locals():
             logger.error(f"JSON response text failed to decode: {roadmap_response.text}")
        logger.error(f"JSON tá»« Gemini khÃ´ng há»£p lá»‡: {e}")
        raise HTTPException(status_code=500, detail="Lá»—i Ä‘á»‹nh dáº¡ng JSON tá»« AI")
    except Exception as e:
        logger.error(f"Lá»—i táº¡o Roadmap: {e}")
        raise HTTPException(status_code=500, detail=f"Lá»—i táº¡o lá»™ trÃ¬nh: {str(e)}")
    
# --- HÃ€M 3: TRUY XUáº¤T ROADMAP (FIXED) ---

def get_user_roadmap(user_id: str):
    """Truy xuáº¥t roadmap gáº§n nháº¥t cá»§a ngÆ°á»i dÃ¹ng tá»« admin_supabase."""
    try:
        res = (
            admin_supabase.table("roadmaps")
            .select("id, level, data, created_at")   # â† CHá»ˆ SELECT CÃC Cá»˜T Cá»¤ THá»‚ (khÃ´ng dÃ¹ng *)
            .eq("user_id", user_id)
            .order("created_at", desc=True)
            .limit(1)
            .maybe_single()
            .execute()
        )

        # Náº¿u khÃ´ng cÃ³ báº£n ghi => tráº£ vá» None
        if not getattr(res, "data", None):
            logger.info(f"[get_user_roadmap] No roadmap found for user_id={user_id}")
            return None

        return res.data

    except Exception as e:
        logger.exception(f"[get_user_roadmap] Lá»—i truy xuáº¥t roadmap: {e}")
        return None
    
def check_week_completion(current_progress: Dict[str, Any], completed_week_data: Dict[str, Any]) -> bool:
    """
    Kiá»ƒm tra xem táº¥t cáº£ cÃ¡c Task trong tuáº§n Ä‘Ã£ hoÃ n thÃ nh (SUCCESS) 
    hay Ä‘Ã£ háº¿t lÆ°á»£t thá»­ (END_OF_ATTEMPTS) hay chÆ°a.
    """
    
    # Láº¥y danh sÃ¡ch Lesson ID cá»§a tuáº§n Ä‘Ã³
    all_lesson_ids_in_week = []
    
    for section in ['grammar', 'vocabulary', 'speaking']:
        items = completed_week_data.get(section, {}).get('items', [])
        
        # ğŸš¨ Sá»¬A Lá»–I: DÃ¹ng .get() vÃ  lá»c cÃ¡c Task khÃ´ng cÃ³ ID Ä‘á»ƒ trÃ¡nh KeyError
        for item in items:
            lesson_id = item.get('lesson_id')
            if lesson_id is None:
                logger.warning(f"âš ï¸ Task bá»‹ thiáº¿u 'lesson_id' trong tuáº§n {completed_week_data.get('week_number')}: {item}")
                continue # Bá» qua item nÃ y vÃ  tiáº¿p tá»¥c

            all_lesson_ids_in_week.append(lesson_id)
        
    if not all_lesson_ids_in_week:
        return False # Tuáº§n khÃ´ng cÃ³ Task nÃ o

    for lesson_id in all_lesson_ids_in_week:
        progress = current_progress.get(lesson_id)
        
        # Náº¿u Task chÆ°a Ä‘Æ°á»£c thá»±c hiá»‡n láº§n nÃ o (None) hoáº·c cÃ³ tráº¡ng thÃ¡i PENDING
        if progress is None or progress.get('status') == 'PENDING':
            # Náº¿u cÃ³ báº¥t ká»³ Task nÃ o cÃ²n PENDING, tuáº§n há»c CHÆ¯A káº¿t thÃºc
            return False 

    # Náº¿u táº¥t cáº£ cÃ¡c Task Ä‘á»u lÃ  SUCCESS hoáº·c END_OF_ATTEMPTS
    return True

def get_week_data_by_lesson_id(lesson_id: str, roadmap_data: Dict[str, Any]) -> Dict[str, Any] | None:
    """
    Duyá»‡t qua Roadmap Ä‘á»ƒ tÃ¬m báº£n ghi cá»§a Tuáº§n chá»©a lesson_id nÃ y.
    """
    for phase in roadmap_data.get('learning_phases', []):
        for week in phase.get('weeks', []):
            for section in ['grammar', 'vocabulary', 'speaking']:
                items = week.get(section, {}).get('items', [])
                # Kiá»ƒm tra náº¿u báº¥t ká»³ item nÃ o cÃ³ lesson_id khá»›p
                if any(item.get('lesson_id') == lesson_id for item in items):
                    return week
    return None
# def get_week_data_by_lesson_id(lesson_id: str, roadmap_data: Dict[str, Any]) -> Dict[str, Any] | None:
#     """Duyá»‡t qua Roadmap Ä‘á»ƒ tÃ¬m báº£n ghi cá»§a Tuáº§n chá»©a lesson_id nÃ y."""
#     for phase in roadmap_data.get('learning_phases', []):
#         for week in phase.get('weeks', []):
#             for section in ['grammar', 'vocabulary', 'speaking']:
#                 items = week.get(section, {}).get('items', [])
#                 if any(item.get('lesson_id') == lesson_id for item in items):
#                     return week
#     return None

async def create_weekly_summary_record(
    user_id: str,
    completed_week_data: Dict[str, Any],
    current_progress: Dict[str, Any],
    admin_supabase
) -> Union[Dict, bool]:

    try:
        week_number = completed_week_data["week_number"]
        first_item = next(
            iter(completed_week_data.get("grammar", {}).get("items", [])),
            None
        )
        phase = first_item["lesson_id"].split("_")[0] if first_item else "P0"

    except Exception as e:
        logger.error(f"âŒ Invalid completed_week_data structure: {e}")
        return False

    def _aggregate_and_insert_sync():

        summaries = {}
        total_tasks = 0
        resolved_tasks = 0
        review_required = False

        for skill in ["grammar", "vocabulary", "speaking"]:
            items = completed_week_data.get(skill, {}).get("items", [])
            scores = []
            review_topics = []
            completed = 0

            for item in items:
                lesson_id = item["lesson_id"]
                topic = item.get("title", "Unknown")
                progress = current_progress.get(lesson_id, {})

                status = progress.get("status")
                score = progress.get("score", 0)

                total_tasks += 1

                if status in ("SUCCESS", "END_OF_ATTEMPTS"):
                    resolved_tasks += 1

                if status == "SUCCESS":
                    completed += 1
                    scores.append(score)

                elif status == "END_OF_ATTEMPTS":
                    review_topics.append(topic)
                    scores.append(score)
                    review_required = True

            avg_score = round(sum(scores) / len(scores), 2) if scores else 0

            summaries[f"{skill}_summary"] = {
                "completed_tasks": completed,
                "review_tasks": review_topics,
                "avg_score": avg_score if skill != "vocabulary" else None,
                "avg_mastery": avg_score if skill == "vocabulary" else None
            }

        completion_rate = round(
            resolved_tasks / total_tasks, 4
        ) if total_tasks > 0 else 0

        insert_data = {
            "user_id": user_id,
            "phase": phase,
            "week_number": week_number,
            "speaking_summary": summaries["speaking_summary"],
            "grammar_summary": summaries["grammar_summary"],
            "vocabulary_summary": summaries["vocabulary_summary"],
            "completion_rate": completion_rate,
            "review_required": review_required
        }

        result = (
            admin_supabase
            .table("weekly_learning_summary")
            .insert(insert_data)
            .execute()
        )

        return result.data[0] if result.data else False

    try:
        record = await anyio.to_thread.run_sync(_aggregate_and_insert_sync)
        logger.info(f"âœ… Weekly Summary P{phase}_W{week_number} inserted")
        return record

    except Exception as e:
        logger.error(f"âŒ Failed to insert weekly summary: {e}")
        return False
    
logger = logging.getLogger(__name__)

# --- HÃ€M Má»šI: ÄIá»€U CHá»ˆNH ROADMAP Báº°NG AI ---

async def generate_and_apply_adaptive_roadmap(
    user_id: str,
    weekly_summary_record: Dict[str, Any], # Báº£n ghi tÃ³m táº¯t tuáº§n N
    current_roadmap_data: Dict[str, Any], # ToÃ n bá»™ Roadmap
    admin_supabase
) -> bool:
    """
    Sá»­ dá»¥ng AI Ä‘á»ƒ phÃ¢n tÃ­ch káº¿t quáº£ tuáº§n trÆ°á»›c (N) vÃ  Ä‘iá»u chá»‰nh ná»™i dung tuáº§n sau (N+1).
    """
    phase_index = -1
    last_week_index = -1
    next_phase_index = -1
    # 1. XÃC Äá»ŠNH TUáº¦N Vá»ªA Káº¾T THÃšC VÃ€ TUáº¦N TIáº¾P THEO
    try:
        last_week_number = weekly_summary_record.get('week_number')
        
        # Láº¥y nhÃ£n Phase ngáº¯n gá»n tá»« Summary (VÃ­ dá»¥: 'P1')
        raw_phase_label = weekly_summary_record.get('phase') 
        
        if not raw_phase_label:
            logger.error("Phase label 'phase' not found in summary record.")
            return False

        # ğŸš¨ Sá»¬A Lá»–I #1: CHUáº¨N HÃ“A Phase Label ('P1' -> 'Phase 1')
        # Logic: TÃ¬m kiáº¿m P (hoáº·c báº¥t ká»³ chá»¯ cÃ¡i nÃ o) theo sau lÃ  sá»‘
        match = re.match(r'[A-Z](\d+)', raw_phase_label, re.IGNORECASE)
        if match:
             # Táº¡o chuá»—i tÃ¬m kiáº¿m hoÃ n háº£o: VÃ­ dá»¥: P1 -> Phase 1
             search_phase_label = f"Phase {match.group(1)}"
        else:
             # Fallback náº¿u Ä‘á»‹nh dáº¡ng khÃ´ng pháº£i Px
             search_phase_label = raw_phase_label
        
        # --- DEBUG KHÃ“A TÃŒM KIáº¾M ---
        logger.debug(f"DEBUG: Searching for Phase Label: {search_phase_label}") 
        logger.debug(f"DEBUG: Target Week Number: {last_week_number}")
        # ----------------------------

        # ğŸš¨ Sá»¬A Lá»–I #2: TÃ¬m kiáº¿m Phase index. DÃ¹ng `in` Ä‘á»ƒ tÃ¬m 'Phase 1' 
        # bÃªn trong chuá»—i dÃ i "Phase 1: Building Active Foundations".
        phase_index_completed = next( # Äá»•i tÃªn biáº¿n Ä‘á»ƒ giá»¯ index cá»§a Phase vá»«a hoÃ n thÃ nh
            i for i, p in enumerate(current_roadmap_data['learning_phases']) 
            if p.get('phase_name') and search_phase_label in p['phase_name']
        )
        
        # TÃ¬m index cá»§a tuáº§n vá»«a káº¿t thÃºc
        last_week_index = next(
            i for i, w in enumerate(current_roadmap_data['learning_phases'][phase_index_completed]['weeks']) 
            if w.get('week_number') == last_week_number
        )

        next_phase_index = phase_index_completed # Index Phase cho tuáº§n má»›i (máº·c Ä‘á»‹nh lÃ  Phase cÅ©)
        
        # 1a. TÃ¬m dá»¯ liá»‡u Tuáº§n Má»›i (N+1)
        if last_week_index + 1 < len(current_roadmap_data['learning_phases'][phase_index_completed]['weeks']):
            # Tuáº§n tiáº¿p theo trong cÃ¹ng Phase
            next_week_index = last_week_index + 1
            # Sá»­ dá»¥ng phase_index_completed Ä‘á»ƒ tham chiáº¿u Phase hiá»‡n táº¡i
            next_week_data_ref = current_roadmap_data['learning_phases'][phase_index_completed]['weeks'][next_week_index]
        
        elif phase_index_completed + 1 < len(current_roadmap_data['learning_phases']):
            # Tuáº§n Ä‘áº§u tiÃªn cá»§a Phase tiáº¿p theo
            next_phase_index = phase_index_completed + 1 # Cáº­p nháº­t chá»‰ má»¥c Phase tiáº¿p theo
            next_week_index = 0
            # Sá»­ dá»¥ng next_phase_index Ä‘Ã£ cáº­p nháº­t
            next_week_data_ref = current_roadmap_data['learning_phases'][next_phase_index]['weeks'][next_week_index] 
        else:
            logger.info(f"ğŸ’¡ [ROADMAP] NgÆ°á»i dÃ¹ng Ä‘Ã£ hoÃ n thÃ nh toÃ n bá»™ Roadmap.")
            return True
        next_week_data_base = next_week_data_ref.copy() # Dá»¯ liá»‡u tuáº§n N+1 gá»‘c

    except (StopIteration, IndexError) as e:
        logger.error(f"âŒ Lá»—i tÃ¬m kiáº¿m Phase/Week trong Roadmap: {e}")
        return False
    next_phase_name = current_roadmap_data['learning_phases'][next_phase_index]['phase_name']

# TrÃ­ch xuáº¥t sá»‘ Phase tá»« tÃªn (VÃ­ dá»¥: '2' tá»« 'Phase 2')
    match = re.search(r'Phase (\d+)', next_phase_name)
    if match:
        # Táº¡o nhÃ£n Phase Ä‘á»™ng (VÃ­ dá»¥: 'P2')
        dynamic_phase_label = f"P{match.group(1)}" 
    else:
        dynamic_phase_label = "Px"
        # 2. XÃ‚Y Dá»°NG PROMPT CHO AI ÄIá»€U CHá»ˆNH
    
    # Chuyá»ƒn dá»¯ liá»‡u tuáº§n N+1 gá»‘c sang JSON string Ä‘á»ƒ truyá»n vÃ o Prompt
    next_week_json = json.dumps(next_week_data_base, indent=2, ensure_ascii=False)
    logger.debug(f"Next week JSON (before adjustment): {next_week_json}")
    prompt = build_roadmap_adjustment_prompt(
        last_week_number=last_week_number,
        weekly_summary_record=json.dumps(weekly_summary_record, indent=2, ensure_ascii=False), # Cáº§n Ä‘áº£m báº£o Ä‘Ã¢y lÃ  chuá»—i JSON
        next_week_data_base=next_week_data_base,
        next_week_json=json.dumps(next_week_data_base, indent=2, ensure_ascii=False), # Cáº§n Ä‘áº£m báº£o Ä‘Ã¢y lÃ  chuá»—i JSON
        dynamic_phase_label=dynamic_phase_label
    )
    # prompt = f"""
    # You are a Personalized Learning Roadmap Adjustment System. Your task is to thoroughly analyze the learning results from the previous week in order to adjust the learning content for the following week.

    # 1. PREVIOUS WEEK ASSESSMENT DATA (Week {last_week_number}):
    # {json.dumps(weekly_summary_record, indent=2, ensure_ascii=False)}

    # 2. NEXT WEEK ROADMAP STRUCTURE (Week {next_week_data_base.get('week_number')} â€“ ORIGINAL JSON FORMAT):
    # {next_week_json}

    # YOUR ADJUSTMENT RULES:
    #     - If there are any Tasks in the 'review_tasks' list of Grammar, Vocabulary, or Speaking, **insert** these Tasks at the **beginning** of the 'items' list of the corresponding topic in the next weekâ€™s structure.

    #     - FOR NEW REVIEW TASKS:
    #         - Must include the key **"type": "review"**.
    #         - The "title" key must have the prefix **"REVIEW: "**.
    #         - **MUST** include the **"lesson_id"** key with a unique format, in which the 5th character represents the corresponding skill symbol (G, V, or S). For example:
    #             * Grammar Review: **{dynamic_phase_label}_W{next_week_data_base.get('week_number')}_G_Review1**
    #             * Vocabulary Review: **{dynamic_phase_label}_W{next_week_data_base.get('week_number')}_V_Review1**
    #             * Speaking Review: **{dynamic_phase_label}_W{next_week_data_base.get('week_number')}_S_Review1**

    #     - If the average score of a skill (avg_score or avg_mastery) is too low (below 0.6), you may **remove** 1 or 2 new theory/vocabulary Tasks in Week N+1 to reduce workload.
    #     - DO NOT change 'week_number' and 'phase' under any circumstances.
    #     - DO NOT add any explanatory text; return **ONLY the JSON OBJECT** of the **ADJUSTED NEXT WEEK ROADMAP STRUCTURE** (including week_number, grammar, vocabulary, speaking, etc.).

    # Please return the adjusted JSON of the NEXT WEEK ROADMAP STRUCTURE in English.
    # """
    # 3. Gá»ŒI GEMINI VÃ€ Xá»¬ LÃ Káº¾T QUáº¢
    client = genai.Client()
    try:
        def _call_gemini_sync():
            return client.models.generate_content(
                model="gemini-2.5-flash",
                contents=prompt,
                config=g_types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )

        response = await anyio.to_thread.run_sync(_call_gemini_sync)

        modified_next_week_data = json.loads(response.text)
        logger.info(f"âœ… AI Ä‘Ã£ hoÃ n táº¥t Ä‘iá»u chá»‰nh cho Tuáº§n {modified_next_week_data.get('week_number')}.")
        
    except (APIError, json.JSONDecodeError) as e:
        logger.error(f"âŒ Lá»—i AI hoáº·c JSON khi Ä‘iá»u chá»‰nh Roadmap: {e}. Sáº½ sá»­ dá»¥ng cáº¥u trÃºc Roadmap gá»‘c.")
        modified_next_week_data = next_week_data_base # DÃ¹ng cáº¥u trÃºc gá»‘c náº¿u AI tháº¥t báº¡i
    except Exception as e:
        logger.error(f"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh trong quÃ¡ trÃ¬nh gá»i AI: {e}")
        modified_next_week_data = next_week_data_base 


    # 4. Cáº¬P NHáº¬T ROADMAP CUá»I CÃ™NG (Thay tháº¿ tuáº§n cÅ© vÃ  chÃ¨n tuáº§n má»›i Ä‘Ã£ chá»‰nh sá»­a)
    
    # 4a. ÄÃ¡nh dáº¥u tuáº§n N lÃ  COMPLETED
    # current_roadmap_data['learning_phases'][phase_index]['weeks'][last_week_index]['status'] = 'COMPLETED'
    def get_all_valid_lesson_ids(roadmap_data: Dict[str, Any]) -> set:
        """Thu tháº­p táº¥t cáº£ lesson_id Ä‘ang tá»“n táº¡i trong Roadmap."""
        valid_ids = set()
        for phase in roadmap_data.get('learning_phases', []):
            for week in phase.get('weeks', []):
                for section in ['grammar', 'vocabulary', 'speaking']:
                    items = week.get(section, {}).get('items', [])
                    for item in items:
                        # DÃ¹ng .get() Ä‘á»ƒ trÃ¡nh crash vÃ  láº¥y ID há»£p lá»‡
                        lesson_id = item.get('lesson_id')
                        if lesson_id:
                            valid_ids.add(lesson_id)
        return valid_ids

    def cleanup_user_progress(roadmap_data: Dict[str, Any], user_progress: Dict[str, Any]) -> Dict[str, Any]:
        """Loáº¡i bá» cÃ¡c Task Ä‘Ã£ bá»‹ xÃ³a khá»i Roadmap khá»i user_progress."""
        valid_ids = get_all_valid_lesson_ids(roadmap_data)
        
        # Chá»‰ giá»¯ láº¡i cÃ¡c má»¥c trong user_progress cÃ³ ID náº±m trong valid_ids
        cleaned_progress = {
            lesson_id: progress_data 
            for lesson_id, progress_data in user_progress.items() 
            if lesson_id in valid_ids
        }
        
        # Ghi log cÃ¡c Task bá»‹ xÃ³a (tÃ¹y chá»n)
        removed_tasks = set(user_progress.keys()) - set(cleaned_progress.keys())
        if removed_tasks:
            logger.info(f"ğŸ—‘ï¸ ÄÃ£ dá»n dáº¹p {len(removed_tasks)} Task khá»i user_progress: {removed_tasks}")

        return cleaned_progress
    # 4b. Thay tháº¿ tuáº§n N+1 gá»‘c báº±ng cáº¥u trÃºc Ä‘Ã£ Ä‘Æ°á»£c AI Ä‘iá»u chá»‰nh
    current_roadmap_data['learning_phases'][next_phase_index]['weeks'][next_week_index] = modified_next_week_data
    def sync_new_tasks(roadmap_data, user_progress):
        # Láº¥y dá»¯ liá»‡u tuáº§n má»›i Ä‘Ã£ Ä‘Æ°á»£c AI chá»‰nh sá»­a
        new_week = roadmap_data['learning_phases'][next_phase_index]['weeks'][next_week_index]
        
        for category in ['grammar', 'speaking', 'vocabulary']:
            if category in new_week:
                # Kiá»ƒm tra xem khÃ³a 'items' cÃ³ tá»“n táº¡i khÃ´ng
                items = new_week[category].get('items', []) 
                
                for item in items:
                    # ğŸš¨ Sá»¬A Lá»–I: DÃ¹ng .get() Ä‘á»ƒ trÃ¡nh KeyError náº¿u AI tráº£ vá» cáº¥u trÃºc thiáº¿u
                    lesson_id = item.get('lesson_id') 
                    
                    if lesson_id and lesson_id not in user_progress:
                        # ThÃªm Task má»›i (bao gá»“m cáº£ Task Review) vÃ o user_progress vá»›i tráº¡ng thÃ¡i PENDING
                        user_progress[lesson_id] = {
                            "type": category,
                            "score": None,
                            "status": "PENDING",
                            "completed": False,
                            "attempt_count": 0
                        }
        return user_progress

    # Thá»±c hiá»‡n Ä‘á»“ng bá»™ hÃ³a
    current_roadmap_data['user_progress'] = cleanup_user_progress(
        current_roadmap_data, 
        current_roadmap_data['user_progress']
            )
    current_roadmap_data['user_progress'] = sync_new_tasks(current_roadmap_data, current_roadmap_data['user_progress'])
    
    # 5. LÆ¯U ROADMAP ÄÃƒ Cáº¬P NHáº¬T VÃ€O DB
    def _save_roadmap_sync():
        result = admin_supabase.table("roadmaps") \
            .update({"data": current_roadmap_data}) \
            .eq("user_id", user_id) \
            .execute()
        return result.data

    try:
        await anyio.to_thread.run_sync(_save_roadmap_sync)
        logger.info("âœ… Roadmap Ä‘Ã£ Ä‘Æ°á»£c lÆ°u thÃ nh cÃ´ng vá»›i Ä‘iá»u chá»‰nh tá»« AI.")
        return True
    except Exception as e:
        logger.error(f"âŒ Lá»—i lÆ°u Roadmap sau khi Ä‘iá»u chá»‰nh AI: {e}")
        return False