# backend/fastapi_app/services/assessment_service.py

from typing import Dict, List, Any
from tempfile import NamedTemporaryFile
from fastapi import UploadFile, HTTPException, Request
from fastapi_app.schemas.test_schemas import PreferenceData, FinalAssessmentSubmission, QuizQuestion 
import os
import json
import logging
from google import genai
from google.genai import types as g_types
from starlette.concurrency import run_in_threadpool
from google.genai.errors import APIError
import base64, mimetypes
from fastapi_app.database import admin_supabase
from fastapi_app.prompts.roadmap import build_roadmap_prompt
import re # Import th∆∞ vi·ªán regex

logger = logging.getLogger(__name__)

# T·∫≠n d·ª•ng client ƒë√£ kh·ªüi t·∫°o ·ªü ph·∫°m vi global t·ª´ test_service
try:
    from .test_service import client, GEMINI_MODEL 
except ImportError:
    client = None
    GEMINI_MODEL = "gemini-2.0-flash"


# --- H√ÄM 1: STT V√Ä PH√ÇN T√çCH TRANSCRIPT ---

async def run_stt_and_analysis_sync(audio_path: str, client):
    """Th·ª±c hi·ªán Speech-to-Text (STT) v√† t√≠nh s·ªë t·ª´."""
    def _sync_call():
        with open(audio_path, "rb") as f:
            audio_data = f.read()

        return client.models.generate_content(
            model="models/gemini-2.0-flash",
            contents=[
                {
                    "role": "user",
                    "parts": [
                        {"text": "Please transcribe this audio."},
                        {
                            "inline_data": {
                                "mime_type": "audio/mpeg", # Gi·∫£ ƒë·ªãnh mime_type ph·ªï bi·∫øn
                                "data": audio_data,
                            }
                        }
                    ]
                }
            ]
        )

    response = await run_in_threadpool(_sync_call)
    transcript = response.text
    word_count = len(transcript.split())  # t√≠nh s·ªë t·ª´ trong transcript

    return {
        "transcript": transcript,
        "word_count": word_count
    }
    
async def analyze_transcript_with_gemini(transcript: str, client: genai.Client) -> str:
    """G·ªçi Gemini ƒë·ªÉ ƒë√°nh gi√° ng·ªØ ph√°p/t·ª´ v·ª±ng trong transcript c·ªßa ng∆∞·ªùi d√πng."""
    analysis_prompt = f"Ph√¢n t√≠ch vƒÉn b·∫£n: '{transcript}' v·ªÅ l·ªói ng·ªØ ph√°p, ch·∫•t l∆∞·ª£ng t·ª´ v·ª±ng, v√† ƒë∆∞a ra 2 g·ª£i √Ω c·∫£i thi·ªán."
    try:
        analysis_response = await run_in_threadpool(
            client.models.generate_content,
            model=GEMINI_MODEL,
            contents=[analysis_prompt]
        )
        return analysis_response.text.strip()
    except Exception as e:
        logger.error(f"L·ªói ph√¢n t√≠ch Transcript LLM: {e}")
        return "L·ªói ph√¢n t√≠ch. Vui l√≤ng th·ª≠ l·∫°i b√†i n√≥i."


# --- H√ÄM 2: CH·∫§M ƒêI·ªÇM TR·∫ÆC NGHI·ªÜM TH·ª∞C T·∫æ ---

def calculate_mcq_score(
    mcq_answers: Dict[str, str] | None, 
    quiz_questions: List[QuizQuestion] 
) -> Dict[str, Any]: 
    """H√†m t√≠nh ƒëi·ªÉm tr·∫Øc nghi·ªám (MCQ) b·∫±ng c√°ch so s√°nh v·ªõi c√¢u tr·∫£ l·ªùi LLM."""
    
    if mcq_answers is None:
        mcq_answers = {}
        
    total_answered = len(mcq_answers)
    correct_count = 0
    topic_results = {} 
    
    correct_data_map = {}
    for q in quiz_questions:
        if q.question_type != 'speaking_prompt':
            correct_data_map[str(q.id)] = {
                'correct_key': q.correct_answer_key, 
                'topic': q.question_type 
            }
            
    for q_id, user_key in mcq_answers.items():
        quiz_data = correct_data_map.get(q_id)
        
        if quiz_data:
            topic = quiz_data['topic']
            correct_answer = quiz_data['correct_key']
            
            if topic not in topic_results:
                topic_results[topic] = [0, 0]  # [correct, total]
            
            topic_results[topic][1] += 1
            
            if correct_answer == user_key:
                correct_count += 1
                topic_results[topic][0] += 1
            
    weak_topics = []
    WEAK_THRESHOLD = 0.60 
    
    for topic, (correct, total) in topic_results.items():
        if total > 0 and (correct / total) < WEAK_THRESHOLD:
            weak_topics.append(f"{topic} (ƒê√∫ng: {correct}/{total})")

    if not weak_topics and total_answered > 0:
          weak_topics.append("Kh√¥ng ph√°t hi·ªán ƒëi·ªÉm y·∫øu l·ªõn ·ªü ph·∫ßn tr·∫Øc nghi·ªám.")

    score_percent = (correct_count / total_answered) * 100 if total_answered > 0 else 0
    
    return {
        "score_percent": score_percent,
        "correct_count": correct_count,
        "total_questions": total_answered,
        "weak_topics": weak_topics,
        # "estimated_level": "Intermediate (B1)" if score_percent >= 60 else "Pre-Intermediate (A2)",
    }

# -----------------------------------------------------------------

async def analyze_and_generate_roadmap(
    payload_data: FinalAssessmentSubmission,
    audio_files: Dict[str, UploadFile]
) -> Dict[str, Any]:
    if client is None:
        raise HTTPException(status_code=500, detail="Gemini Client kh√¥ng kh·∫£ d·ª•ng.")

    # Ch·ªâ log audio files
    logger.info(f"üìå FILE MAP NH·∫¨N T·ª™ FRONTEND: {list(audio_files.keys())}")

    # --- 1. PH√ÇN T√çCH MCQ ---
    mcq_analysis = calculate_mcq_score(payload_data.mcq_answers, payload_data.quiz_questions)
    diagnostic_summary = mcq_analysis 
    
    # --- 2. X·ª¨ L√ù SPEAKING ---
    full_speaking_analysis = []

    # T·∫°o map t·ª´ file_key (d√π frontend g·ª≠i g√¨) v·ªÅ t√™n file th·ª±c t·∫ø trong form
    file_key_to_form_key = {}
    for form_key in audio_files.keys():
        # form_key c√≥ th·ªÉ l√† 'audio_file_21' ho·∫∑c 'audio_file_21[]' ho·∫∑c 'audio_21' t√πy frontend
        logger.debug(f"Processing form_key for mapping: {form_key}")
        if isinstance(form_key, str):
            key = form_key
            # direct numeric extraction
            if key.startswith("audio_file_"):
                num = key.replace("audio_file_", "")
                file_key_to_form_key[num] = form_key
                try:
                    file_key_to_form_key[int(num)] = form_key
                except ValueError:
                    pass
            else:
                # try extract last numeric part
                m = re.search(r"(\d+)", key)
                if m:
                    num = m.group(1)
                    file_key_to_form_key[num] = form_key
                    try:
                        file_key_to_form_key[int(num)] = form_key
                    except ValueError:
                        pass
                # also map the raw key itself
                file_key_to_form_key[key] = form_key

    logger.info(f"[service] File key mapping (after scan): {file_key_to_form_key}")

    # Log speaking_data coming in payload for debug
    try:
        logger.info(f"[service] speaking_data payload: {payload_data.speaking_data}")
    except Exception:
        logger.exception("Kh√¥ng th·ªÉ log speaking_data")

    for speaking_data_item in payload_data.speaking_data:
        raw_key = speaking_data_item.file_key
        logger.info(f"[service] Raw file_key t·ª´ frontend: {raw_key} (type: {type(raw_key)})")

        # Chu·∫©n h√≥a key: th·ª≠ t·∫•t c·∫£ c√°c kh·∫£ nƒÉng
        possible_keys = []
        try:
            raw_key_str = str(raw_key).strip()
            possible_keys = [
                raw_key_str,
                raw_key_str.lstrip("Qq"),
                raw_key_str.replace("question_", ""),
                f"audio_file_{raw_key_str}",
                f"audio_{raw_key_str}",
            ]
        except Exception:
            possible_keys = [str(raw_key)]

        # N·∫øu raw_key l√† s·ªë d·∫°ng int/float
        if isinstance(raw_key, (int, float)):
            possible_keys.append(str(int(raw_key)))

        # Deduplicate
        seen = set()
        possible_keys = [k for k in possible_keys if not (k in seen or seen.add(k))]

        logger.debug(f"[service] possible_keys to try for raw_key {raw_key}: {possible_keys}")

        matched_form_key = None
        for k in possible_keys:
            # 1) direct in mapping dict
            if k in file_key_to_form_key:
                matched_form_key = file_key_to_form_key[k]
                logger.info(f"[service] matched via file_key_to_form_key: {k} -> {matched_form_key}")
                break
            # 2) direct form key present
            if k in audio_files:
                matched_form_key = k
                logger.info(f"[service] matched direct form key: {k}")
                break
            # 3) try with audio_file_ prefix
            prefix = f"audio_file_{k}"
            if prefix in audio_files:
                matched_form_key = prefix
                logger.info(f"[service] matched with prefix: {prefix}")
                break

        audio_file = audio_files.get(matched_form_key) if matched_form_key else None

        if not audio_file:
            logger.warning(f"Kh√¥ng t√¨m th·∫•y audio cho file_key={raw_key} (ƒë√£ th·ª≠: {possible_keys})")
            logger.warning(f"C√°c key c√≥ s·∫µn: {list(audio_files.keys())}")
            # fallback: n·∫øu ch·ªâ c√≥ 1 file, gi·∫£ s·ª≠ map v√†o ƒë√≥ (ch·ªâ ƒë·ªÉ debug, c√≥ th·ªÉ lo·∫°i b·ªè s·∫£n xu·∫•t)
            if len(audio_files) == 1 and not full_speaking_analysis: # Ch·ªâ d√πng fallback n·∫øu ƒë√¢y l√† file ƒë·∫ßu ti√™n
                only_key = list(audio_files.keys())[0]
                logger.warning(f"[service] Fallback: ch·ªâ c√≥ 1 file upload, d√πng {only_key}")
                audio_file = audio_files.get(only_key)
            else:
                continue
        else:
            logger.info(f"ƒê√É T√åM TH·∫§Y audio cho Q{raw_key}: {matched_form_key} -> filename: {getattr(audio_file,'filename',None)}")

        # --- Ki·ªÉm tra nhanh n·ªôi dung file (size) tr∆∞·ªõc khi ghi temp ---
        try:
            # ·ªû ƒë√¢y ch·ªâ ƒë·ªÉ log size approximate n·∫øu c√≥ attribute .file
            file_obj = audio_file.file
            file_obj.seek(0, 2)
            size = file_obj.tell()
            file_obj.seek(0)
            logger.info(f"[service] File info - key: {matched_form_key}, filename: {getattr(audio_file,'filename',None)}, size_bytes: {size}")
        except Exception:
            logger.exception("Kh√¥ng th·ªÉ l·∫•y file size")

        # --- T·ª´ ƒë√¢y gi·ªØ nguy√™n x·ª≠ l√Ω file ---
        tmp_path = None
        try:
            file_content = await audio_file.read()
            suffix = os.path.splitext(audio_file.filename)[1] or ".mp3"

            with NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                tmp_path = tmp.name
                await run_in_threadpool(tmp.write, file_content)

            logger.info(f"[service] Vi·∫øt t·∫°m file: {tmp_path}")

            # STT
            stt_result = await run_stt_and_analysis_sync(tmp_path, client)

            # Gemini Grammar
            llm_comment = await analyze_transcript_with_gemini(stt_result['transcript'], client)

            full_speaking_analysis.append({
                "question_id": raw_key,
                "transcript": stt_result['transcript'],
                "word_count": stt_result['word_count'],
                "latency_s": speaking_data_item.latency_ms / 1000,
                "llm_grammar_comment": llm_comment,
            })

        except Exception as e:
            logger.exception(f"L·ªói x·ª≠ l√Ω audio cho Q{raw_key}: {e}")

        finally:
            if tmp_path and os.path.exists(tmp_path):
                try:
                    os.unlink(tmp_path)
                except:
                    pass
    
    # --- 3. X√ÇY D·ª∞NG PROMPT CHO GEMINI v√† t·∫°o roadmap ---
    prefs = payload_data.preferences
    prefs_dict = prefs.model_dump()

    weak_points_list = list(mcq_analysis.get('weak_topics', []))
    has_speaking = len(full_speaking_analysis) > 0
    if has_speaking and full_speaking_analysis[0]['latency_s'] > 1.5:
        weak_points_list.append("Ph·∫£n x·∫° ch·∫≠m (Latency > 1.5s)")

    speaking_transcript = full_speaking_analysis[0]['transcript'] if has_speaking else "Kh√¥ng c√≥ d·ªØ li·ªáu n√≥i."

    # C·∫¨P NH·∫¨T PROMPT ƒê·ªÇ T·∫†O C·∫§U TR√öC JSON CHI TI·∫æT THEO Y√äU C·∫¶U
    roadmap_prompt = build_roadmap_prompt(
        mcq_analysis=mcq_analysis,
        weak_points_list=weak_points_list,
        speaking_transcript=speaking_transcript,
        prefs_dict=prefs_dict,
    )

    try:
        roadmap_response = await run_in_threadpool(
            client.models.generate_content,
            model=GEMINI_MODEL,
            contents=[roadmap_prompt],
            config=g_types.GenerateContentConfig(response_mime_type="application/json")
        )

        roadmap_json = json.loads(roadmap_response.text)
        ai_assessed_level = roadmap_json.get("estimated_level", "Unknown")
        user_summary = roadmap_json.get("user_summary", "Kh√¥ng c√≥ t√≥m t·∫Øt.")
        raw_roadmap = roadmap_json.get("roadmap", {})

        # C·∫¨P NH·∫¨T LOGIC X·ª¨ L√ù: TR√çCH XU·∫§T TR·ª∞C TI·∫æP C·∫§U TR√öC TU·∫¶N
        final_learning_phases = []
        for idx, phase in enumerate(raw_roadmap.get("learning_phases", [])):
            phase_name = phase.get("phase_name") or f"Giai ƒëo·∫°n {idx + 1}"
            duration_weeks = phase.get("duration_weeks", 0)
            weeks = phase.get("weeks", [])

            # ƒê·∫£m b·∫£o c·∫•u tr√∫c tu·∫ßn ƒë∆∞·ª£c gi·ªØ nguy√™n, s·ª≠ d·ª•ng Dict cho grammar/vocab/speaking
            standardized_weeks = []
            for week in weeks:
                standardized_weeks.append({
                    "week_number": week.get("week_number"),
                    "grammar": week.get("grammar", {}), # L·∫•y d∆∞·ªõi d·∫°ng Dict, m·∫∑c ƒë·ªãnh l√† {}
                    "vocabulary": week.get("vocabulary", {}), # L·∫•y d∆∞·ªõi d·∫°ng Dict, m·∫∑c ƒë·ªãnh l√† {}
                    "speaking": week.get("speaking", {}), # L·∫•y d∆∞·ªõi d·∫°ng Dict, m·∫∑c ƒë·ªãnh l√† {}
                    "expected_outcome": week.get("expected_outcome", "")
                })

            final_learning_phases.append({
                "phase_name": phase_name,
                "duration_weeks": duration_weeks,
                "weeks": standardized_weeks,
            })


        final_roadmap = {
            "user_summary": user_summary, 
            "level": ai_assessed_level,
            "summary": raw_roadmap.get("summary", "T√≥m t·∫Øt kh√¥ng c√≥ s·∫µn do l·ªói LLM."),
            "current_status": raw_roadmap.get("current_status", f"M·ª•c ti√™u: {prefs_dict['communication_goal']}, Th·ªùi gian: {prefs_dict['target_duration']}"),
            "daily_plan_recommendation": raw_roadmap.get("daily_plan_recommendation", f"Khuy·∫øn ngh·ªã: H·ªçc {prefs_dict['daily_commitment']} m·ªói ng√†y."),
            "learning_phases": final_learning_phases,
            "diagnostic_summary": mcq_analysis,
            "speaking_transcripts": full_speaking_analysis
        }
        
        # --- 4. L∆ØU ROADMAP V√ÄO admin_supabase ---
        try:
            # 1. Th·ª±c hi·ªán xo√° t·∫•t c·∫£ roadmap hi·ªán c√≥ c·ªßa user n√†y
            # L·ªánh delete s·∫Ω xo√° t·∫•t c·∫£ d√≤ng kh·ªõp v·ªõi user_id
            admin_supabase.table("roadmaps") \
                .delete() \
                .eq("user_id", payload_data.user_id) \
                .execute()
            
            logger.info(f"üóëÔ∏è ƒê√£ xo√° l·ªô tr√¨nh c≈© c·ªßa user {payload_data.user_id}")

            # 2. Chu·∫©n b·ªã d·ªØ li·ªáu m·ªõi ho√†n to√†n
            insert_data = {
                "user_id": payload_data.user_id,
                "level": ai_assessed_level,
                "data": final_roadmap,
            }

            # 3. Ch√®n (Insert) b·∫£n ghi m·ªõi nh·∫•t v√†o b·∫£ng
            result = admin_supabase.table("roadmaps") \
                .insert(insert_data) \
                .execute()
            
            logger.info(f"‚ú® ƒê√£ l∆∞u l·ªô tr√¨nh m·ªõi th√†nh c√¥ng cho user {payload_data.user_id}")

        except Exception as e:
            # Ghi log chi ti·∫øt l·ªói n·∫øu thao t√°c database th·∫•t b·∫°i
            logger.error(f"‚ùå L·ªói khi l√†m m·ªõi roadmap trong admin_supabase: {e}")
            
        return {
            "status": "success",
            "message": "Roadmap created",
            "roadmap_details": {
                "roadmap": final_roadmap,
                "diagnostic_summary": mcq_analysis
            },
            "diagnostic_summary": mcq_analysis,
            "speaking_transcripts": full_speaking_analysis
        }

    except json.JSONDecodeError as e:
        # Log ƒë·∫ßy ƒë·ªß response text n·∫øu c√≥ th·ªÉ ƒë·ªÉ debug l·ªói JSON
        if 'roadmap_response' in locals():
             logger.error(f"JSON response text failed to decode: {roadmap_response.text}")
        logger.error(f"JSON t·ª´ Gemini kh√¥ng h·ª£p l·ªá: {e}")
        raise HTTPException(status_code=500, detail="L·ªói ƒë·ªãnh d·∫°ng JSON t·ª´ AI")
    except Exception as e:
        logger.error(f"L·ªói t·∫°o Roadmap: {e}")
        raise HTTPException(status_code=500, detail=f"L·ªói t·∫°o l·ªô tr√¨nh: {str(e)}")
    
# --- H√ÄM 3: TRUY XU·∫§T ROADMAP (FIXED) ---

def get_user_roadmap(user_id: str):
    """Truy xu·∫•t roadmap g·∫ßn nh·∫•t c·ªßa ng∆∞·ªùi d√πng t·ª´ admin_supabase."""
    try:
        res = (
            admin_supabase.table("roadmaps")
            .select("id, level, data, created_at")   # ‚Üê CH·ªà SELECT C√ÅC C·ªòT C·ª§ TH·ªÇ (kh√¥ng d√πng *)
            .eq("user_id", user_id)
            .order("created_at", desc=True)
            .limit(1)
            .maybe_single()
            .execute()
        )

        # N·∫øu kh√¥ng c√≥ b·∫£n ghi => tr·∫£ v·ªÅ None
        if not getattr(res, "data", None):
            logger.info(f"[get_user_roadmap] No roadmap found for user_id={user_id}")
            return None

        return res.data

    except Exception as e:
        logger.exception(f"[get_user_roadmap] L·ªói truy xu·∫•t roadmap: {e}")
        return None