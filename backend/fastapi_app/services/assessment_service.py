# backend/fastapi_app/services/assessment_service.py

from typing import Dict, List, Any
from tempfile import NamedTemporaryFile
from fastapi import UploadFile, HTTPException, Request
from fastapi_app.schemas.test_schemas import PreferenceData, FinalAssessmentSubmission, QuizQuestion 
import os
import json
import logging
from google import genai
from google.genai import types as g_types
from starlette.concurrency import run_in_threadpool
from google.genai.errors import APIError
import base64, mimetypes
from fastapi_app.database import admin_supabase
import re # Import thÆ° viá»‡n regex

logger = logging.getLogger(__name__)

# Táº­n dá»¥ng client Ä‘Ã£ khá»Ÿi táº¡o á»Ÿ pháº¡m vi global tá»« test_service
try:
    from .test_service import client, GEMINI_MODEL 
except ImportError:
    client = None
    GEMINI_MODEL = "gemini-2.0-flash"


# --- HÃ€M 1: STT VÃ€ PHÃ‚N TÃCH TRANSCRIPT ---

async def run_stt_and_analysis_sync(audio_path: str, client):
    """Thá»±c hiá»‡n Speech-to-Text (STT) vÃ  tÃ­nh sá»‘ tá»«."""
    def _sync_call():
        with open(audio_path, "rb") as f:
            audio_data = f.read()

        return client.models.generate_content(
            model="models/gemini-2.0-flash",
            contents=[
                {
                    "role": "user",
                    "parts": [
                        {"text": "Please transcribe this audio."},
                        {
                            "inline_data": {
                                "mime_type": "audio/mpeg", # Giáº£ Ä‘á»‹nh mime_type phá»• biáº¿n
                                "data": audio_data,
                            }
                        }
                    ]
                }
            ]
        )

    response = await run_in_threadpool(_sync_call)
    transcript = response.text
    word_count = len(transcript.split())  # tÃ­nh sá»‘ tá»« trong transcript

    return {
        "transcript": transcript,
        "word_count": word_count
    }
    
async def analyze_transcript_with_gemini(transcript: str, client: genai.Client) -> str:
    """Gá»i Gemini Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ ngá»¯ phÃ¡p/tá»« vá»±ng trong transcript cá»§a ngÆ°á»i dÃ¹ng."""
    analysis_prompt = f"PhÃ¢n tÃ­ch vÄƒn báº£n: '{transcript}' vá» lá»—i ngá»¯ phÃ¡p, cháº¥t lÆ°á»£ng tá»« vá»±ng, vÃ  Ä‘Æ°a ra 2 gá»£i Ã½ cáº£i thiá»‡n."
    try:
        analysis_response = await run_in_threadpool(
            client.models.generate_content,
            model=GEMINI_MODEL,
            contents=[analysis_prompt]
        )
        return analysis_response.text.strip()
    except Exception as e:
        logger.error(f"Lá»—i phÃ¢n tÃ­ch Transcript LLM: {e}")
        return "Lá»—i phÃ¢n tÃ­ch. Vui lÃ²ng thá»­ láº¡i bÃ i nÃ³i."


# --- HÃ€M 2: CHáº¤M ÄIá»‚M TRáº®C NGHIá»†M THá»°C Táº¾ ---

def calculate_mcq_score(
    mcq_answers: Dict[str, str] | None, 
    quiz_questions: List[QuizQuestion] 
) -> Dict[str, Any]: 
    """HÃ m tÃ­nh Ä‘iá»ƒm tráº¯c nghiá»‡m (MCQ) báº±ng cÃ¡ch so sÃ¡nh vá»›i cÃ¢u tráº£ lá»i LLM."""
    
    if mcq_answers is None:
        mcq_answers = {}
        
    total_answered = len(mcq_answers)
    correct_count = 0
    topic_results = {} 
    
    correct_data_map = {}
    for q in quiz_questions:
        if q.question_type != 'speaking_prompt':
            correct_data_map[str(q.id)] = {
                'correct_key': q.correct_answer_key, 
                'topic': q.question_type 
            }
            
    for q_id, user_key in mcq_answers.items():
        quiz_data = correct_data_map.get(q_id)
        
        if quiz_data:
            topic = quiz_data['topic']
            correct_answer = quiz_data['correct_key']
            
            if topic not in topic_results:
                topic_results[topic] = [0, 0]  # [correct, total]
            
            topic_results[topic][1] += 1
            
            if correct_answer == user_key:
                correct_count += 1
                topic_results[topic][0] += 1
            
    weak_topics = []
    WEAK_THRESHOLD = 0.60 
    
    for topic, (correct, total) in topic_results.items():
        if total > 0 and (correct / total) < WEAK_THRESHOLD:
            weak_topics.append(f"{topic} (ÄÃºng: {correct}/{total})")

    if not weak_topics and total_answered > 0:
          weak_topics.append("KhÃ´ng phÃ¡t hiá»‡n Ä‘iá»ƒm yáº¿u lá»›n á»Ÿ pháº§n tráº¯c nghiá»‡m.")

    score_percent = (correct_count / total_answered) * 100 if total_answered > 0 else 0
    
    return {
        "score_percent": score_percent,
        "correct_count": correct_count,
        "total_questions": total_answered,
        "weak_topics": weak_topics,
        # "estimated_level": "Intermediate (B1)" if score_percent >= 60 else "Pre-Intermediate (A2)",
    }

# -----------------------------------------------------------------

async def analyze_and_generate_roadmap(
    payload_data: FinalAssessmentSubmission,
    audio_files: Dict[str, UploadFile]
) -> Dict[str, Any]:
    if client is None:
        raise HTTPException(status_code=500, detail="Gemini Client khÃ´ng kháº£ dá»¥ng.")

    # Chá»‰ log audio files
    logger.info(f"ğŸ“Œ FILE MAP NHáº¬N Tá»ª FRONTEND: {list(audio_files.keys())}")

    # --- 1. PHÃ‚N TÃCH MCQ ---
    mcq_analysis = calculate_mcq_score(payload_data.mcq_answers, payload_data.quiz_questions)
    diagnostic_summary = mcq_analysis 
    
    # --- 2. Xá»¬ LÃ SPEAKING ---
    full_speaking_analysis = []

    # Táº¡o map tá»« file_key (dÃ¹ frontend gá»­i gÃ¬) vá» tÃªn file thá»±c táº¿ trong form
    file_key_to_form_key = {}
    for form_key in audio_files.keys():
        # form_key cÃ³ thá»ƒ lÃ  'audio_file_21' hoáº·c 'audio_file_21[]' hoáº·c 'audio_21' tÃ¹y frontend
        logger.debug(f"Processing form_key for mapping: {form_key}")
        if isinstance(form_key, str):
            key = form_key
            # direct numeric extraction
            if key.startswith("audio_file_"):
                num = key.replace("audio_file_", "")
                file_key_to_form_key[num] = form_key
                try:
                    file_key_to_form_key[int(num)] = form_key
                except ValueError:
                    pass
            else:
                # try extract last numeric part
                m = re.search(r"(\d+)", key)
                if m:
                    num = m.group(1)
                    file_key_to_form_key[num] = form_key
                    try:
                        file_key_to_form_key[int(num)] = form_key
                    except ValueError:
                        pass
                # also map the raw key itself
                file_key_to_form_key[key] = form_key

    logger.info(f"[service] File key mapping (after scan): {file_key_to_form_key}")

    # Log speaking_data coming in payload for debug
    try:
        logger.info(f"[service] speaking_data payload: {payload_data.speaking_data}")
    except Exception:
        logger.exception("KhÃ´ng thá»ƒ log speaking_data")

    for speaking_data_item in payload_data.speaking_data:
        raw_key = speaking_data_item.file_key
        logger.info(f"[service] Raw file_key tá»« frontend: {raw_key} (type: {type(raw_key)})")

        # Chuáº©n hÃ³a key: thá»­ táº¥t cáº£ cÃ¡c kháº£ nÄƒng
        possible_keys = []
        try:
            raw_key_str = str(raw_key).strip()
            possible_keys = [
                raw_key_str,
                raw_key_str.lstrip("Qq"),
                raw_key_str.replace("question_", ""),
                f"audio_file_{raw_key_str}",
                f"audio_{raw_key_str}",
            ]
        except Exception:
            possible_keys = [str(raw_key)]

        # Náº¿u raw_key lÃ  sá»‘ dáº¡ng int/float
        if isinstance(raw_key, (int, float)):
            possible_keys.append(str(int(raw_key)))

        # Deduplicate
        seen = set()
        possible_keys = [k for k in possible_keys if not (k in seen or seen.add(k))]

        logger.debug(f"[service] possible_keys to try for raw_key {raw_key}: {possible_keys}")

        matched_form_key = None
        for k in possible_keys:
            # 1) direct in mapping dict
            if k in file_key_to_form_key:
                matched_form_key = file_key_to_form_key[k]
                logger.info(f"[service] matched via file_key_to_form_key: {k} -> {matched_form_key}")
                break
            # 2) direct form key present
            if k in audio_files:
                matched_form_key = k
                logger.info(f"[service] matched direct form key: {k}")
                break
            # 3) try with audio_file_ prefix
            prefix = f"audio_file_{k}"
            if prefix in audio_files:
                matched_form_key = prefix
                logger.info(f"[service] matched with prefix: {prefix}")
                break

        audio_file = audio_files.get(matched_form_key) if matched_form_key else None

        if not audio_file:
            logger.warning(f"KhÃ´ng tÃ¬m tháº¥y audio cho file_key={raw_key} (Ä‘Ã£ thá»­: {possible_keys})")
            logger.warning(f"CÃ¡c key cÃ³ sáºµn: {list(audio_files.keys())}")
            # fallback: náº¿u chá»‰ cÃ³ 1 file, giáº£ sá»­ map vÃ o Ä‘Ã³ (chá»‰ Ä‘á»ƒ debug, cÃ³ thá»ƒ loáº¡i bá» sáº£n xuáº¥t)
            if len(audio_files) == 1 and not full_speaking_analysis: # Chá»‰ dÃ¹ng fallback náº¿u Ä‘Ã¢y lÃ  file Ä‘áº§u tiÃªn
                only_key = list(audio_files.keys())[0]
                logger.warning(f"[service] Fallback: chá»‰ cÃ³ 1 file upload, dÃ¹ng {only_key}")
                audio_file = audio_files.get(only_key)
            else:
                continue
        else:
            logger.info(f"ÄÃƒ TÃŒM THáº¤Y audio cho Q{raw_key}: {matched_form_key} -> filename: {getattr(audio_file,'filename',None)}")

        # --- Kiá»ƒm tra nhanh ná»™i dung file (size) trÆ°á»›c khi ghi temp ---
        try:
            # á» Ä‘Ã¢y chá»‰ Ä‘á»ƒ log size approximate náº¿u cÃ³ attribute .file
            file_obj = audio_file.file
            file_obj.seek(0, 2)
            size = file_obj.tell()
            file_obj.seek(0)
            logger.info(f"[service] File info - key: {matched_form_key}, filename: {getattr(audio_file,'filename',None)}, size_bytes: {size}")
        except Exception:
            logger.exception("KhÃ´ng thá»ƒ láº¥y file size")

        # --- Tá»« Ä‘Ã¢y giá»¯ nguyÃªn xá»­ lÃ½ file ---
        tmp_path = None
        try:
            file_content = await audio_file.read()
            suffix = os.path.splitext(audio_file.filename)[1] or ".mp3"

            with NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                tmp_path = tmp.name
                await run_in_threadpool(tmp.write, file_content)

            logger.info(f"[service] Viáº¿t táº¡m file: {tmp_path}")

            # STT
            stt_result = await run_stt_and_analysis_sync(tmp_path, client)

            # Gemini Grammar
            llm_comment = await analyze_transcript_with_gemini(stt_result['transcript'], client)

            full_speaking_analysis.append({
                "question_id": raw_key,
                "transcript": stt_result['transcript'],
                "word_count": stt_result['word_count'],
                "latency_s": speaking_data_item.latency_ms / 1000,
                "llm_grammar_comment": llm_comment,
            })

        except Exception as e:
            logger.exception(f"Lá»—i xá»­ lÃ½ audio cho Q{raw_key}: {e}")

        finally:
            if tmp_path and os.path.exists(tmp_path):
                try:
                    os.unlink(tmp_path)
                except:
                    pass
    
    # --- 3. XÃ‚Y Dá»°NG PROMPT CHO GEMINI vÃ  táº¡o roadmap ---
    prefs = payload_data.preferences
    prefs_dict = prefs.model_dump()

    weak_points_list = list(mcq_analysis.get('weak_topics', []))
    has_speaking = len(full_speaking_analysis) > 0
    if has_speaking and full_speaking_analysis[0]['latency_s'] > 1.5:
        weak_points_list.append("Pháº£n xáº¡ cháº­m (Latency > 1.5s)")

    speaking_transcript = full_speaking_analysis[0]['transcript'] if has_speaking else "KhÃ´ng cÃ³ dá»¯ liá»‡u nÃ³i."

    # Cáº¬P NHáº¬T PROMPT Äá»‚ Táº O Cáº¤U TRÃšC JSON CHI TIáº¾T THEO YÃŠU Cáº¦U
    roadmap_prompt = f"""
    Báº¡n lÃ  chuyÃªn gia thiáº¿t káº¿ lá»™ trÃ¬nh há»c tiáº¿ng Anh giao tiáº¿p cÃ¡ nhÃ¢n hÃ³a. 
    Báº¡n PHáº¢I tráº£ vá» Ä‘Ãºng vÃ  duy nháº¥t má»™t JSON há»£p lá»‡, khÃ´ng cÃ³ báº¥t ká»³ ná»™i dung nÃ o khÃ¡c ngoÃ i JSON.

    ThÃ´ng tin ngÆ°á»i há»c:
    - Káº¿t quáº£ tráº¯c nghiá»‡m: {mcq_analysis}
    - Äiá»ƒm yáº¿u ná»•i báº­t: {", ".join(weak_points_list) if weak_points_list else "ChÆ°a xÃ¡c Ä‘á»‹nh rÃµ"}
    - Transcript nÃ³i máº«u: "{speaking_transcript}"
    - Cam káº¿t há»c má»—i ngÃ y: {prefs_dict['daily_commitment']}
    - Má»¥c tiÃªu giao tiáº¿p: {prefs_dict['communication_goal']}
    - Thá»i gian mong muá»‘n Ä‘áº¡t má»¥c tiÃªu: {prefs_dict['target_duration']}

    YÃªu cáº§u nghiÃªm ngáº·t:
    1. PhÃ¢n tÃ­ch káº¿t quáº£ MCQ ({mcq_analysis}), ká»¹ nÄƒng nÃ³i ({speaking_transcript}) vÃ  pháº£n xáº¡ (latency) Ä‘á»ƒ tá»± Ä‘Ã¡nh giÃ¡ trÃ¬nh Ä‘á»™ hiá»‡n táº¡i cá»§a ngÆ°á»i há»c (vÃ­ dá»¥: A1, A2, B1...).
    2. Viáº¿t nháº­n xÃ©t tá»•ng quan (150-250 tá»«) báº±ng tiáº¿ng Viá»‡t cho key **"user_summary"**.
    3. Táº¡o lá»™ trÃ¬nh há»c chi tiáº¿t phÃ¹ há»£p vá»›i level cá»§a ngÆ°á»i há»c vÃ  cáº£i thiá»‡n Ä‘Æ°á»£c Ä‘iá»ƒm yáº¿u cá»§a há», chia thÃ nh 2-4 giai Ä‘oáº¡n (phase).
    4. Má»—i giai Ä‘oáº¡n PHáº¢I chá»©a máº£ng **"weeks"**.
    5. Trong má»—i tuáº§n, cÃ¡c key **"grammar"**, **"vocabulary"**, **"speaking"** PHáº¢I cÃ³ cáº¥u trÃºc phá»©c há»£p bao gá»“m **"title"**, **"lesson_id"**, vÃ  máº£ng **"items"** chi tiáº¿t (Ã­t nháº¥t 2 items).

    TRáº¢ Vá»€ CHá»ˆ Má»˜T JSON DUY NHáº¤T THEO ÄÃšNG Cáº¤U TRÃšC SAU:

    {{
    "user_summary": "Nháº­n xÃ©t tá»•ng quan báº±ng tiáº¿ng Viá»‡t (50-100 tá»«)...",
    "estimated_level": "VÃ­ dá»¥: Pre-Intermediate (A2)",  <-- AI Tá»° ÄIá»€N VÃ€O ÄÃ‚Y
    "roadmap": {{
        "summary": "TÃ³m táº¯t ngáº¯n gá»n lá»™ trÃ¬nh trong 1-2 cÃ¢u",
        "current_status": "Má»¥c tiÃªu: {prefs_dict['communication_goal']} â€¢ Thá»i gian mong muá»‘n: {prefs_dict['target_duration']}",
        "daily_plan_recommendation": "Khuyáº¿n nghá»‹ há»c {prefs_dict['daily_commitment']} má»—i ngÃ y, táº­p trung nÃ³i + tá»« vá»±ng",
        "learning_phases": [
        {{
            "phase_name": "Giai Ä‘oáº¡n 1: XÃ¢y dá»±ng ná»n táº£ng",
            "duration_weeks": 4,
            "weeks": [
            {{
                "week_number": 1,
                "grammar": {{
                    "title": "Present Simple & Present Continuous (review, cÃ¡ch dÃ¹ng, cáº¥u trÃºc)",
                    "lesson_id": "P1_W1_Grammar",
                    "items": [
                        {{"title": "Ngá»¯ phÃ¡p Present Simple", "lesson_id": "P1_W1_G_Theory1"}},
                        {{"title": "Ngá»¯ phÃ¡p Present Continuous", "lesson_id": "P1_W1_G_Theory2"}},
                    ]
                }},
                "vocabulary": {{
                    "title": "Daily routines, family, hobbies",
                    "lesson_id": "P1_W1_Vocab",
                    "items": [
                        {{"title": "Tá»« vá»±ng vá» Daily routines (10 tá»«)", "lesson_id": "P1_W1_V_Theory1"}},
                        {{"title": "Tá»« vá»±ng vá» Family (20)", "lesson_id": "P1_W1_V_Theory2"}},
                        {{"title": "hobbies (25)", "lesson_id": "P1_W1_V_Theory3"}},

                    ]
                }},
                "speaking": {{
                    "title": "Giá»›i thiá»‡u báº£n thÃ¢n, nÃ³i vá» 1 ngÃ y cá»§a báº¡n (1-2 phÃºt)",
                    "lesson_id": "P1_W1_Speaking",
                    "items": [
                        {{"title": "Há»™i thoáº¡i chá»§ Ä‘á» giá»›i thiá»‡u báº£n thÃ¢n", "lesson_id": "P1_W1_S_conversation1"}},
			            {{"title": "Há»™i thoáº¡i chá»§ Ä‘á» 1 ngÃ y cá»§a báº¡n", "lesson_id": "P1_W1_S_conversation2"}},
                    ]
                }},
                "expected_outcome": "NÃ³i trÃ´i cháº£y cÃ¢u cÆ¡ báº£n vá» báº£n thÃ¢n vÃ  thÃ³i quen hÃ ng ngÃ y"
            }},
            {{
                "week_number": 2,
                "grammar": {{
                    "title": "CÃ¢u cáº§u khiáº¿n & CÃ¢u tráº§n thuáº­t",
                    "lesson_id": "P1_W2_Grammar",
                    "items": [
                        {{"title": "CÃ¢u cáº§u khiáº¿n", "lesson_id": "P1_W2_G_Theory1"}},
                        {{"title": "CÃ¢u tráº§n thuáº­t", "lesson_id": "P1_W2_G_Theory2"}},
                    ]
                }},
                "vocabulary": {{
                    "title": "Du lá»‹ch & áº¨m thá»±c",
                    "lesson_id": "P1_W2_Vocab",
                    "items": [
                        {{"title": "Tá»« vá»±ng vá» du lá»‹ch", "lesson_id": "P1_W2_V_Theory1"}},
                        {{"title": "Tá»« vá»±ng vá» áº©m thá»±c", "lesson_id": "P1_W2_V_Theory2"}}
                    ]
                }},
                "speaking": {{
                    "title": "Ká»ƒ láº¡i má»™t tráº£i nghiá»‡m du lá»‹ch gáº§n Ä‘Ã¢y (2 phÃºt)",
                    "lesson_id": "P1_W2_Speaking",
                    "items": [
                        {{"title": "Há»™i thoáº¡i ká»ƒ láº¡i má»™t tráº£i nghiá»‡m du lá»‹ch gáº§n Ä‘Ã¢y", "lesson_id": "P1_W1_S_conversation1"}},
                    ]
                }},
                "expected_outcome": "Ká»ƒ chuyá»‡n quÃ¡ khá»© cÃ³ sá»­ dá»¥ng má»‘c thá»i gian"
            }}
            ]
        }}
        ]
    }}
    }}

    QUAN TRá»ŒNG:
    - Tá»•ng sá»‘ tuáº§n cá»§a táº¥t cáº£ cÃ¡c giai Ä‘oáº¡n pháº£i há»£p lÃ½ vá»›i thá»i gian má»¥c tiÃªu ({prefs_dict['target_duration']}).
    - Táº­p trung kháº¯c phá»¥c Ä‘iá»ƒm yáº¿u: {", ".join(weak_points_list) if weak_points_list else "cÃ¢n báº±ng cÃ¡c ká»¹ nÄƒng"}.
    - Speaking task pháº£i thá»±c táº¿, cÃ³ thá»ƒ ghi Ã¢m vÃ  tá»± sá»­a.
    - Expected outcome pháº£i Ä‘o lÆ°á»ng Ä‘Æ°á»£c (thá»i lÆ°á»£ng nÃ³i, sá»‘ lá»—i, Ä‘á»™ trÃ´i cháº£y...).

    Báº¯t Ä‘áº§u ngay báº±ng JSON, khÃ´ng viáº¿t gÃ¬ thÃªm.
    """

    try:
        roadmap_response = await run_in_threadpool(
            client.models.generate_content,
            model=GEMINI_MODEL,
            contents=[roadmap_prompt],
            config=g_types.GenerateContentConfig(response_mime_type="application/json")
        )

        roadmap_json = json.loads(roadmap_response.text)
        ai_assessed_level = roadmap_json.get("estimated_level", "Unknown")
        user_summary = roadmap_json.get("user_summary", "KhÃ´ng cÃ³ tÃ³m táº¯t.")
        raw_roadmap = roadmap_json.get("roadmap", {})

        # Cáº¬P NHáº¬T LOGIC Xá»¬ LÃ: TRÃCH XUáº¤T TRá»°C TIáº¾P Cáº¤U TRÃšC TUáº¦N
        final_learning_phases = []
        for idx, phase in enumerate(raw_roadmap.get("learning_phases", [])):
            phase_name = phase.get("phase_name") or f"Giai Ä‘oáº¡n {idx + 1}"
            duration_weeks = phase.get("duration_weeks", 0)
            weeks = phase.get("weeks", [])

            # Äáº£m báº£o cáº¥u trÃºc tuáº§n Ä‘Æ°á»£c giá»¯ nguyÃªn, sá»­ dá»¥ng Dict cho grammar/vocab/speaking
            standardized_weeks = []
            for week in weeks:
                standardized_weeks.append({
                    "week_number": week.get("week_number"),
                    "grammar": week.get("grammar", {}), # Láº¥y dÆ°á»›i dáº¡ng Dict, máº·c Ä‘á»‹nh lÃ  {}
                    "vocabulary": week.get("vocabulary", {}), # Láº¥y dÆ°á»›i dáº¡ng Dict, máº·c Ä‘á»‹nh lÃ  {}
                    "speaking": week.get("speaking", {}), # Láº¥y dÆ°á»›i dáº¡ng Dict, máº·c Ä‘á»‹nh lÃ  {}
                    "expected_outcome": week.get("expected_outcome", "")
                })

            final_learning_phases.append({
                "phase_name": phase_name,
                "duration_weeks": duration_weeks,
                "weeks": standardized_weeks,
            })


        final_roadmap = {
            "user_summary": user_summary, 
            "level": ai_assessed_level,
            "summary": raw_roadmap.get("summary", "TÃ³m táº¯t khÃ´ng cÃ³ sáºµn do lá»—i LLM."),
            "current_status": raw_roadmap.get("current_status", f"Má»¥c tiÃªu: {prefs_dict['communication_goal']}, Thá»i gian: {prefs_dict['target_duration']}"),
            "daily_plan_recommendation": raw_roadmap.get("daily_plan_recommendation", f"Khuyáº¿n nghá»‹: Há»c {prefs_dict['daily_commitment']} má»—i ngÃ y."),
            "learning_phases": final_learning_phases,
            "diagnostic_summary": mcq_analysis,
            "speaking_transcripts": full_speaking_analysis
        }
        
        # --- 4. LÆ¯U ROADMAP VÃ€O admin_supabase ---
        try:
            # 1. Thá»±c hiá»‡n xoÃ¡ táº¥t cáº£ roadmap hiá»‡n cÃ³ cá»§a user nÃ y
            # Lá»‡nh delete sáº½ xoÃ¡ táº¥t cáº£ dÃ²ng khá»›p vá»›i user_id
            admin_supabase.table("roadmaps") \
                .delete() \
                .eq("user_id", payload_data.user_id) \
                .execute()
            
            logger.info(f"ğŸ—‘ï¸ ÄÃ£ xoÃ¡ lá»™ trÃ¬nh cÅ© cá»§a user {payload_data.user_id}")

            # 2. Chuáº©n bá»‹ dá»¯ liá»‡u má»›i hoÃ n toÃ n
            insert_data = {
                "user_id": payload_data.user_id,
                "level": ai_assessed_level,
                "data": final_roadmap,
            }

            # 3. ChÃ¨n (Insert) báº£n ghi má»›i nháº¥t vÃ o báº£ng
            result = admin_supabase.table("roadmaps") \
                .insert(insert_data) \
                .execute()
            
            logger.info(f"âœ¨ ÄÃ£ lÆ°u lá»™ trÃ¬nh má»›i thÃ nh cÃ´ng cho user {payload_data.user_id}")

        except Exception as e:
            # Ghi log chi tiáº¿t lá»—i náº¿u thao tÃ¡c database tháº¥t báº¡i
            logger.error(f"âŒ Lá»—i khi lÃ m má»›i roadmap trong admin_supabase: {e}")
            
        return {
            "status": "success",
            "message": "Roadmap created",
            "roadmap_details": {
                "roadmap": final_roadmap,
                "diagnostic_summary": mcq_analysis
            },
            "diagnostic_summary": mcq_analysis,
            "speaking_transcripts": full_speaking_analysis
        }

    except json.JSONDecodeError as e:
        # Log Ä‘áº§y Ä‘á»§ response text náº¿u cÃ³ thá»ƒ Ä‘á»ƒ debug lá»—i JSON
        if 'roadmap_response' in locals():
             logger.error(f"JSON response text failed to decode: {roadmap_response.text}")
        logger.error(f"JSON tá»« Gemini khÃ´ng há»£p lá»‡: {e}")
        raise HTTPException(status_code=500, detail="Lá»—i Ä‘á»‹nh dáº¡ng JSON tá»« AI")
    except Exception as e:
        logger.error(f"Lá»—i táº¡o Roadmap: {e}")
        raise HTTPException(status_code=500, detail=f"Lá»—i táº¡o lá»™ trÃ¬nh: {str(e)}")
    
# --- HÃ€M 3: TRUY XUáº¤T ROADMAP (FIXED) ---

def get_user_roadmap(user_id: str):
    """Truy xuáº¥t roadmap gáº§n nháº¥t cá»§a ngÆ°á»i dÃ¹ng tá»« admin_supabase."""
    try:
        res = (
            admin_supabase.table("roadmaps")
            .select("id, level, data, created_at")   # â† CHá»ˆ SELECT CÃC Cá»˜T Cá»¤ THá»‚ (khÃ´ng dÃ¹ng *)
            .eq("user_id", user_id)
            .order("created_at", desc=True)
            .limit(1)
            .maybe_single()
            .execute()
        )

        # Náº¿u khÃ´ng cÃ³ báº£n ghi => tráº£ vá» None
        if not getattr(res, "data", None):
            logger.info(f"[get_user_roadmap] No roadmap found for user_id={user_id}")
            return None

        return res.data

    except Exception as e:
        logger.exception(f"[get_user_roadmap] Lá»—i truy xuáº¥t roadmap: {e}")
        return None